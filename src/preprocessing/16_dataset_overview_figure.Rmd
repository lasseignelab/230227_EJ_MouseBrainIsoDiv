---
title: "Dataset Overview Figure"
author: "Emma Jones"
date: "2023-06-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Dataset Overview Figure

The purpose of this script is to provide a dataset overview to serve as manuscript figure 1. It is dependent on scripts 00 and 01 to get sample metadata. It takes less than 3 minutes to run and is not finished but is mainly on the shelf for now.

---
Remaining to do:
- What about nanopore stats/ long-read information
- Transcripts lengths etc
- Consider turning into a table
- X-axis is squished in panel E
- Remove underscores from labels
- delete useless code
---

For code review, I am tracking the amount of time that this analysis will take.

```{r proc time}
ptm <- proc.time()
```

#### Load in packages

```{r load packages}
suppressPackageStartupMessages({
  library(tidyverse)
  library(data.table)
  library(styler)
  library(lintr)
  library(here)
  library(hexbin)
  library(viridis)
})
```

#### Load in data

```{r load in data}
load(here("data", "cpm_out", "cpm_counts_metadata.RData"))

counts_drop0 <- merged_counts_iso[rowSums(merged_counts_iso[, -1]) > 0, ]

gene_counts_drop0 <- merged_counts[rowSums(merged_counts_iso[, -1]) > 0, -1]

both_counts_drop0 <- merged_counts[rowSums(merged_counts_iso[, -1]) > 0, ]

```

## Plot things!!

```{r barplot txs}

EJ_custom_palette <- c('#EEDD88', '#77AADD', '#FFAABB', "#5D69B1", '#EE8866', "#52BCA3", "#99C945", '#99DDFF', '#DDDDDD')

# get number of novel transcripts
txs <- sum(!is.na(str_extract(counts_drop0$isoform_id, "tx*...")))

# create data frame
transcript_data <- data.frame(
  transcript_novelty = c("novel", "annotated"),
  count = c(txs, nrow(counts_drop0) - txs)
)

# barplot
ggplot(transcript_data, aes(
  x = transcript_novelty, y = count,
  fill = transcript_novelty
)) +
  geom_bar(position = "dodge", stat = "identity") +
  scale_fill_viridis(discrete = TRUE, begin = 0.3, end = 0.9) +
  geom_text(aes(label = count),
    position = position_dodge(width = 0.9),
    vjust = -0.25
  )

# save
ggsave(here("results", "plots", "bar_plots", "novel_transcripts_barplot.png"),
  width = 3, height = 4
)
```

```{r barplot genes}
# get number of unique genes
genes <- unique(gene_counts_drop0$GENEID)

# get novel unique genes
gns <- sum(!is.na(str_extract(genes, "gene*...")))

# make into data frame
gene_data <- data.frame(
  gene_novelty = c("novel", "annotated"),
  count = c(gns, length(genes) - gns)
)

# barplot
ggplot(gene_data, aes(x = gene_novelty, y = count, fill = gene_novelty)) +
  geom_bar(position = "dodge", stat = "identity") +
  scale_fill_viridis(discrete = TRUE, begin = 0.2, end = 0.6) +
  geom_text(aes(label = count),
    position = position_dodge(width = 0.9), vjust = -0.25
  )

# save
ggsave(here("results", "plots", "bar_plots", "novel_genes_barplot.png"),
  width = 3, height = 4
)
```

transcripts per gene

```{r get transcripts per gene}
gene_matches <- both_counts_drop0[, 1:2]

tx_per_gene <- gene_matches %>%
  group_by(GENEID) %>%
  summarise(`transcript count` = n(), .groups = "drop")

ggplot(tx_per_gene, aes(x = `transcript count`)) +
  geom_histogram(binwidth = 1) +
  xlim(0, 25)

ggsave(here("results", "plots", "histograms", "transcripts_per_gene.png"))

mean(tx_per_gene$`transcript count`)


```


```{r plot metadata histograms}
# reads per sample
ggplot(sample_collection_metadata, aes(x = total_reads)) +
  geom_histogram(bins = 10)

ggsave(here("results", "plots", "histograms", "reads_per_sample.png"),
  width = 6, height = 4
)

# RIN per sample
ggplot(sample_collection_metadata, aes(x = RIN)) +
  geom_histogram()

# median length per sample
ggplot(sample_collection_metadata, aes(x = med_len)) +
  geom_histogram()

# N50 per sample
ggplot(sample_collection_metadata, aes(x = N50)) +
  geom_histogram()

# geom bar for reads per tissue
ggplot(
  sample_collection_metadata,
  aes(y = total_reads, x = tissue, fill = tissue)
) +
  geom_bar(stat = "identity")

ggsave(here("results", "plots", "bar_plots", "reads_per_sample.png"),
  width = 6, height = 4
)

sum(sample_collection_metadata$total_reads)
```
total reads: 85909493

what are the most highly expressed novel transcripts??

```{r pull highest expressed transcripts}
novel_counts <- merged_counts_iso[merged_counts_iso$isoform_id %like% "tx", ]
novel_counts$means <- apply(novel_counts[, -1], 1, mean)

novel_tx_count_means <- novel_counts[, c(1, 42)]

# compare to annotated
annotated_counts <-
  merged_counts_iso[!merged_counts_iso$isoform_id %like% "tx", ]
annotated_counts$means <- apply(annotated_counts[, -1], 1, mean)

annotated_tx_count_means <- annotated_counts[, c(1, 42)]

# plot - need to data wrangle
merged_counts_iso_means <- merged_counts_iso
merged_counts_iso_means$means <- apply(merged_counts_iso[, -1], 1, mean)

merged_counts_iso_means$novel <- merged_counts_iso$isoform_id %like% "tx"
```

actually, lets see if that agrees when I do to cpm normalized counts

```{r cpm iso}
novel_cpm <- cpm_iso[cpm_iso$isoform_id %like% "tx", ]
novel_cpm$means <- apply(novel_cpm[, -1], 1, mean)

novel_tx_cpm_means <- novel_cpm[, c(1, 42)]
```

Once I get the top novel genes, I can look at their locations using the genome annotation file that we get as an output from bambu.

```{r read in the gtf file}
annotation <- read_table(
  here("data", "nextflow", "bambu", "extended_annotations.gtf"),
  col_names = FALSE
)
```

Here I am manually looking up the chr locataions of the toel novel genes. I should try to automate this somehow but have not gotten to it yet.

### Biological replicate agreement

Another thing we can do to show dataset quality is to show biological replicate agreement for samples that are the same brain region and sex across batches. I'm going to show samples 14 and 6 since they fit that bill.

```{r biological replicate agreement}
ggplot(cpm, aes(x = log2(sample06), y = log2(sample14))) +
  geom_point()

ggplot(cpm, aes(x = log10(sample06), y = log10(sample14))) +
  geom_point()

ggplot(cpm, aes(x = sample06, y = sample14, alpha = 0.1)) +
  geom_point()

ggplot(log2(cpm + 1), aes(x = sample06, y = sample14, alpha = 0.1)) +
  geom_point()

cor(cpm$sample06, cpm$sample16, method = "pearson")

cor.test(cpm$sample09, cpm$sample14, method = "pearson")

ggplot(log10(cpm + 1), aes(x = sample06, y = sample14)) +
  geom_hex(binwidth = c(0.08, 0.13)) +
  scale_fill_viridis_c(limits = c(0, 500))

ggplot(log2(cpm + 1), aes(x = sample06, y = sample14)) +
  geom_hex(binwidth = c(0.3, 0.4)) +
  scale_fill_viridis_c(limits = c(0, 600)) +
  geom_abline(slope = 1, intercept = 0)
```

Expected results: cor 0.9304667, p-value < 2.2e-16

I can also extract the top 50 expressed transcripts for interproscan, though we dont get much information out of this.

```{r extract top 50 expressed novel transcripts}
novel_tx_cpm_means <- novel_tx_cpm_means[order(-novel_tx_cpm_means$means), ]

top50_txs <- head(novel_tx_cpm_means$isoform_id, 50)

write.table(top50_txs,
  here("data", "interproscan", "top50_txs.txt"),
  quote = FALSE,
  row.names = FALSE, col.names = FALSE
)
```

#### Clean up script

```{r tidy script}
style_file("16_dataset_overview_figure.Rmd")

lint("16_dataset_overview_figure.Rmd",
  linters = linters_with_defaults(
    object_length_linter = NULL,
    object_name_linter = NULL,
    object_usage_linter = NULL
  )
)
```

Also, needed to get processing time.

```{r proc time finish}
fptm <- proc.time() - ptm
fptm[3] / 60
```

It says -26 minutes, but I know from timing it myself it only takes 2 minutes to run.

#### Software versions

My software versions will be commented below.

```{r versions}
sessionInfo()
```

R version 4.3.1 (2023-06-16)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 22.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 
LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

time zone: Etc/UTC
tzcode source: system (glibc)

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] viridis_0.6.4     viridisLite_0.4.2 hexbin_1.28.3     here_1.0.1       
 [5] lintr_3.1.0       styler_1.10.1     data.table_1.14.8 lubridate_1.9.2  
 [9] forcats_1.0.0     stringr_1.5.0     dplyr_1.1.2       purrr_1.0.2      
[13] readr_2.1.4       tidyr_1.3.0       tibble_3.2.1      ggplot2_3.4.3    
[17] tidyverse_2.0.0  

loaded via a namespace (and not attached):
 [1] gtable_0.3.4      xfun_0.40         remotes_2.4.2.1   processx_3.8.2   
 [5] lattice_0.21-8    callr_3.7.3       tzdb_0.4.0        vctrs_0.6.3      
 [9] tools_4.3.1       ps_1.7.5          generics_0.1.3    fansi_1.0.4      
[13] pkgconfig_2.0.3   R.oo_1.25.0       desc_1.4.2        lifecycle_1.0.3  
[17] R.cache_0.16.0    compiler_4.3.1    farver_2.1.1      textshaping_0.3.6
[21] munsell_0.5.0     htmltools_0.5.6   yaml_2.3.7        lazyeval_0.2.2   
[25] pillar_1.9.0      crayon_1.5.2      R.utils_2.12.2    tidyselect_1.2.0 
[29] digest_0.6.33     stringi_1.7.12    labeling_0.4.2    rprojroot_2.0.3  
[33] fastmap_1.1.1     grid_4.3.1        colorspace_2.1-0  cli_3.6.1        
[37] magrittr_2.0.3    utf8_1.2.3        withr_2.5.0       scales_1.2.1     
[41] backports_1.4.1   cyclocomp_1.1.0   timechange_0.2.0  rmarkdown_2.24   
[45] gridExtra_2.3     ragg_1.2.5        R.methodsS3_1.8.2 hms_1.1.3        
[49] evaluate_0.21     knitr_1.43        rex_1.2.1         rlang_1.1.1      
[53] glue_1.6.2        xml2_1.3.5        rstudioapi_0.15.0 R6_2.5.1         
[57] systemfonts_1.0.4
